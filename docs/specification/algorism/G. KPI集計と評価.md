# G. KPI集計と評価 

G. KPI集計と評価 — なにを・どうするシステム？

ひとことで
毎日の利用ログや介入ログから “効いているか” を数字で可視化し、意思決定に使える形にまとめる装置です。
* ①日々の原始ログ→集計KPI（実行率・連続日数・リテンション 等）
* ②比較→効果測定（A/B・オフライン評価、信頼区間・効果量）
* ③ダッシュボード表示と実験運用のベストプラクティス（誤検知を避ける・分散を下げる）
A/Bや時系列の“正しい見方”は各社の研究で確立しています（オンライン実験のルール・落とし穴・分散削減など）KDD+4Microsoft+4Microsoft+4。 「小さな変化の検出」にはEWMA（指数加重移動平均）が有効で、一般にλ=0.15〜0.3が微小ドリフトに敏感です NIST ITL。 リテンションの読み方は“時間の定義（24hロール or カレンダー日）”で結果が変わるため、分析側で厳密に決めます amplitude.com。

他システムとの連携（どこから何を受け取り、どこへ返す？）

```text
A: 正規化（T / 0–1）
  -> B: ベイズ統合（Posterior OCEAN_hat, 分散）
    -> C: 確信度＆品質（観測分散, 品質フラグ）
      -> D: 時系列特徴（EWMA/傾き/分散）
        -> E: 介入プランナー（technique, tone, length, CTA）
          -> F: LLM後処理（構造化・安全化・配信用カード）
             -> 【G】KPI集計と評価
                  ├ 集計：実行率／継続日数／リテンション／応答遅延 等
                  ├ 評価：A/B（効果量・信頼区間）、分散削減（CUPED）など
                  └ 可視化：ダッシュ、実験レポート
```
* 入力：配信ログ（F）、ユーザー行動ログ（クリック・実施チェック等）、Eの方策／根拠タグ、B/Dの状態指標。
* 出力：集計KPIテーブル、A/Bの効果推定＋信頼区間、ダッシュボード指標（EWMA等）、改善アラート。
* 実験ベストプラクティスに沿い、解釈の落とし穴や誤警報を避けます（Microsoft/Netflix等の公開知見）Microsoft+1。

KPIカタログ（このプロジェクト版・最小セット）
1) 介入の実行率（Execution Rate）
* 定義：配信カードのうち**実行（チェック、タップ＋完了）**した割合。
* 区間推定：Wilson区間を推奨（小標本・極端比率でも安定）ウィキペディア。
2) 連続日数（Streak）／継続率（Retention）
* Streak：連日実行の最長・現在・平均。
* Retention：コホート基準でD1/D7/D28 等を追跡（ファネル戻り率）。“日”の定義（24hロール or カレンダー）を固定して解釈します amplitude.com+1。
* 中〜長期の離脱を見るなら生存分析（Kaplan–Meier）で中央値継続時間やハザードを評価できます Statology+1。
3) 効果量（Effect Size）と統計的不確実性
* 連続値（例：自己評価スコア）の差は Cohen’s d（標準化平均差）で“大きさ”を示す ウィキペディア+1。
  可読表記：

```text
d = (xbar_1 - xbar_2) / s_pooled
s_pooled = sqrt( ((n1 - 1) * s1^2 + (n2 - 1) * s2^2) / (n1 + n2 - 2) )
```
* 比率差は差のWilson区間または比のログ区間で表現。
4) トレンド系の補助指標
* EWMA・直近傾き・ローリング分散で短期の上がり下がりや不安定化を検知（λの選択で感度調整） NIST ITL。

評価デザイン（信頼できる結論にするコツ）
1. **オンライン実験（A/B）**を基本に
    * “信頼できる実験”のチェックリストや落とし穴（測定漏れ・欠損・誤設計・メトリクス解釈の錯誤）を避ける運用を採用します Microsoft+1。
2. 分散削減（検出力アップ）
    * CUPED：実験前のベースライン等を共変量にして分散を下げる（必要サンプルや期間を節約） ExP Platform。
    * Netflixの事例でも事後の層別／CUPEDの有効性が示されています KDD。
3. “のぞき見（peeking）”防止と解釈
    * 途中での有意判定は誤陽性を増やすため事前の停止規則か逐次法を用意（プラットフォーム側の実装指針に従う）。
4. 長期価値を見るなら“時間”で評価
    * 単なる転換率だけでなく、どれだけ長く続いたかも見るため生存分析を併用（継続の中央値・期間ごとの離脱リスク） Statology。

どう構築する？（実装ロードマップ）
1) データモデル（例）
* behavior_events：配信/閲覧/クリック/実施/完了などの行動ログ
* intervention_plans：Eの方策（technique/tone/length/cta）＋根拠タグ
* kpi_daily：ユーザー×日×技法で実行率・Streak更新・応答遅延
* kpi_cohorts：コホート別のD1/D7/D28や生存テーブル（人数・イベント・打切り）
* experiments / assignments / metrics_ab：A/B割付と結果
2) 集計ジョブ（n8n / SQL＋Python）
* 日次：behavior_events→kpi_daily（実行率・Streak）
* 週次：コホート更新、Wilson区間／Cohen’s d／EWMAの再計算
* 実験：割付ログと事前共変量でCUPEDを適用し効果推定（ノートブック or Pythonバッチ） ExP Platform
3) 指標の数式（抜粋）
* 
￼実行率 $\hat{p} = \frac{\text{実行}}{\text{配信}}$、95%CIはWilson区間（実装は公式式）

効果量（連続）: Cohen's d $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}$ をレポートに併記（p値だけに頼らない）

トレンド : EWMA $z_t = \lambda y_t + (1-\lambda)z_{t-1}$、$\lambda=0.15 \sim 0.3$目安

 
4) ダッシュボード（最小ビュー）
* KPIカード：実行率（Wilson CI付き）、平均Streak、D7/D28リテンション
* トレンド：EWMAと傾き、アラート（3σ超など）
* 実験：A/B差の効果量（d）とCI、CUPED適用の有無

受け入れ基準（例）
1. 実行率の信頼区間をWilsonで計算し、低母数でも破綻しない（ユニットテスト） ウィキペディア
2. 効果量は p値に加えてCohen’s dを表示（解釈可能性が向上） ウィキペディア
3. EWMAは仕様どおりに更新され、λ変更で感度が変わる（再現テスト） NIST ITL
4. CUPEDで分散が減り、必要サンプルが基準より縮小（サンドボックスデータで検証） ExP Platform
5. リテンションは“日定義”を固定してレポート（24hロール／カレンダーの違いを明示） amplitude.com

よくある落とし穴 → 回避策
* p値だけを見てしまう → **効果量（Cohen’s d）**やCIで“大きさ”を併記。ウィキペディア
* “のぞき見”で有意化 → 事前の停止規則・逐次法・プラットフォーム推奨に従う（Microsoft資料のチェックリスト参照）。Microsoft
* 微小効果を見落とす → EWMAで小さなドリフトに敏感に。NIST ITL
* 検出力が足りない → CUPED等の分散削減や共変量調整を導入。ExP Platform
* Retentionの基準がぶれる → “日の定義”とコホート法を文書化して固定。amplitude.com+1

整合性チェック（5回）
1. 前段モジュールとの整合：B/Dの出力（Posterior・EWMA）とE/Fの配信ログを入力に、KPI→実験評価→ダッシュへ一貫。OK。
2. 統計の根拠：Wilson区間・Cohen’s d・EWMA・CUPED・実験運用の出典を明記。OK。Microsoft+4ウィキペディア+4ウィキペディア+4
3. 実務注意：Retentionの時間定義、のぞき見防止、分散削減の段取りを明文化。OK。amplitude.com+1
4. 解釈可能性：p値に依存せず効果量・CIを併記、ダッシュはEWMA等で“変化の形”も提示。OK。ウィキペディア+1
5. 拡張互換：生存分析の追加で中長期の継続を評価可能（コホートKPIと矛盾なし）。OK。Statology

必要なら、このGモジュールのSQL／n8nジョブ雛形、CUPED付きA/Bノートブック、ダッシュ（実行率CI・EWMA・Retention）コンポーネントまで即時に落としてお渡しします。
