# B. ベイズ統合 

B. ベイズ統合って何をするシステム？

超ざっくり言うと、**初回テスト（Prior）と日々のテキスト推定（Likelihood）を「精度（=ばらつきの小ささ）に応じてうまく混ぜる」装置です。混ぜた結果がPosterior（OCEAN_hat）で、以降の可視化や介入プランナーがこれを使います。数学的には正規—正規（Normal–Normal）の組合せだと、“精度重み付き平均”**になります（下式）。精度＝分散の逆数なので、信頼できるほうに重みが多く乗るのがポイントです。Bookdown+2Statlect+2
式（各因子 O, C, E, A, N を独立に更新） Prior 平均 μ₀、分散 σ₀²、観測（テキスト）平均 x、分散 σₓ² のとき Posterior 平均 μₚ = (μ₀/σ₀² + x/σₓ²) / (1/σ₀² + 1/σₓ²) Posterior 分散 σₚ² = 1 / (1/σ₀² + 1/σₓ²) （＝精度和が分母、精度×平均の和が分子。直観解説つきの教科書・講義にも同式）Bookdown+1
この「逐次更新」を連日くり返すと、静止カルマンフィルタと同等の処理になります（線形・ガウスの世界ではカルマンはベイズ更新そのもの）。arXiv+1

どこに・何と連携して動く？
* 入力（from A: スコア整形・正規化）
    * Prior＝オンボーディングで得た IPIP-NEO-120 のTスコアや0–1（両系統保持）
    * Likelihood＝Symanto Big Five APIの**テキスト推定（OCEAN）**を0–1/Tに統一した値
        * Symanto Big Five の API は RapidAPI/公式で公開（OCEAN のテキスト推定）。RapidAPI+2Symanto - Psychology AI+2
* 中核処理（本モジュール）
    * 各因子ごとにμと分散を更新（上の式）し、OCEAN_hatとvar_postを得る
* 出力（to D/図3）
    * ocean_timeseries に Posterior（人向けT・機械向け0–1）＋分散を保存
    * これを介入プランナーが参照して、CBT/WOOP/If–Then の方策強度・トーンを調整
連携面の注意：Posterior 分散は「確信度」そのものです。Planner では「今は不安定だから優しく」「安定だから一歩踏み込む」など強度制御に使えます。

初心者向けにもう一歩：何をどう“混ぜる”の？
1. Prior（初回テスト）は「その人のベース傾向」。パーソナリティは短期には比較的安定で、テスト–再テストのメタ分析でも高い信頼性（多くの領域で 0.8 前後）が確認されています。だから Prior はそこそこ硬い情報。Wiley Online Library+2ResearchGate+2
2. Likelihood（テキスト推定）は「今日の発話から推定」。一方で文の長さ・話題・翻訳の有無などで精度が揺れやすい。
3. ベイズ統合は、硬い Prior と、その日の情報を「ばらつきに応じて配合」します。観測が長文でテーマも合っていればσₓ²が小さく→今日の情報に寄る／短文や翻訳経由ならσₓ²が大きく→Prior に寄る、と自然に決まります。これは「精度＝1/分散で重み付ける」だけの、とても筋の良い混ぜ方です。Bookdown

どう作る？（実装ガイド）
1) 設計：スケールと分散の決め方
* 二系統の単位を常に同時保持
    * 機械用：0–1（*_p01）
    * 人向け：Tスコア（*_T、平均50・SD10）
    * どちらも列で保存し、norm_version をメタで付与（「二重正規化」を防止）
* Prior 分散（σ₀²）の設計
    * 目安としてTの全分散（=10²）に“信頼性”を掛けるなど、硬さの基準を置く（より厳密には古典的テスト理論の分解を用いるが、ここでは実装指針として「ベースラインは比較的精度高い」を反映）。信頼性の実証例は多数（BFI 系で高い内的一貫性・再検査信頼）。Wiley Online Library+1
* 観測分散（σₓ²）の設計
    * APIがconfidence等を返すならそれを一次指標に採用
    * 返さない場合は、テキスト長（長いほど小分散）／翻訳経路ペナルティ／ドメイン一致度などからヒューリスティックで推定（学習で校正）
* 実務上の落とし穴
    * 推定分散の誤差で重みが偏ることがある（小さすぎる分散に支配される等）。ロバスト化として分散に下限・上限を設定し、推定分散の平滑化を推奨。品質注意は NIST/Statistics Canada も言及。NIST+1

2) I/O スキーマ（JSON; 因子は O,C,E,A,N）
入力（A からの正規化結果＋参照 Prior）

```json
{
  "user_id": 123,
  "prior":   { "mu_T": {"O":63,"C":44,"E":52,"A":58,"N":41}, "var_T": {"O":64,"C":81,"E":81,"A":64,"N":81} },
  "obs":     { "x_T":  {"O":60,"C":35,"E":55,"A":62,"N":45}, "var_T": {"O":225,"C":225,"E":225,"A":225,"N":225} },
  "meta":    { "norm_version":"Johnson2014","lang_route":"ja→en","tokens":120 }
}```
出力（時系列へ保存し、図3へ handoff）

```json
{
  "posterior": {
    "mu_T":  {"O":59,"C":40,"E":53,"A":60,"N":43},
    "var_T": {"O":69.2,"C":69.2,"E":69.2,"A":69.2,"N":69.2}
  },
  "posterior_p01": { "O":0.59,"C":0.40,"E":0.53,"A":0.60,"N":0.43 }
}```
上の数字は例。Posterior 分散は Prior/観測より小さくなる（“情報が増えた分だけ精度が上がる”）。Bookdown

3) n8n 実装（Measure フロー中の Function ノード）
1. **前段（A）**で正規化済みの Prior/観測を取得（T と 0–1 の両系統）
2. 各因子で独立更新（T 系列で更新し、0–1は T/100 で併記が簡単）
3. 分散の下限・上限・非常時フォールバック（観測欠損時は μₚ=μ₀, σₚ²=σ₀² など）
4. 監査ログ：使った分散推定値・トークン数・翻訳経路を保存
5. MySQL ノードへ ocean_timeseries に INSERT（Posterior と var、EWMA/傾き/分散は別ジョブ）
擬似コード（JS）

```js
function updateOne(mu0, var0, x, varx) {
  const prec0 = 1/var0, precx = 1/varx;             // 精度
  const mup   = (prec0*mu0 + precx*x) / (prec0+precx);
  const varp  = 1 / (prec0 + precx);
  return [mup, varp];
}

const caps = {minVar: 36, maxVar: 400};             // 分散の上下限（例：SD 6〜20）
for (const k of ["O","C","E","A","N"]) {
  const var0  = clamp(prior.var_T[k],  caps.minVar, caps.maxVar);
  const varx  = clamp(obs.var_T[k],    caps.minVar, caps.maxVar);
  const [mu, v] = updateOne(prior.mu_T[k], var0, obs.x_T[k], varx);
  post.mu_T[k]  = mu;
  post.var_T[k] = v;
  post.mu_p01[k]= Math.max(0, Math.min(1, mu/100));
}
```
逐次更新＝カルマンフィルタの一歩です（状態遷移を入れない静止版）。将来、週単位ドリフトなど遷移モデルを入れるとフル・カルマンになります。arXiv+1
4) 検証（ミニ例）
Prior: μ₀=45, σ₀=10 → σ₀²=100 観測: x=60, σₓ=15 → σₓ²=225 精度：0.01 と 0.00444… → 正規化重みはおよそ 0.692 : 0.308 μₚ ≈ 0.692×45 + 0.308×60 = 49.6 σₚ² = 1/(0.01+0.00444) ≈ 69.2（SD≈8.3） → 両者の“ちょうど中間”ではなく、ばらつきの小さい Prior 側に寄るのがポイント。Bookdown

監視・可視化（おまけ）
日々の Posterior 列を EWMA（指数加重移動平均）や7日傾きで平滑・傾向検知。EWMA の λ（または α）は窓長から決められ、新しいデータに重みを大きくします。実務的な式・解説は統計教材や実務解説に多数あります。math.montana.edu+2ウィキペディア+2

よくある質問（実装の勘どころ）
* Symanto が confidence を返さない場合は？ 「トークン数」「翻訳経路」「同一話題の再現性」などから観測分散を推定して OK。API 自体は「テキストから Big Five を返す」ことが一次情報で確認できます。RapidAPI+1
* 複数観測を一括で混ぜたい 逐次に 1 つずつ更新しても、最終結果は一括更新と一致（正規—正規の性質）。分散が極端に小さいサンプルに引っ張られないよう分散に下限を置くのが実務のコツです。Bookdown+1
* 信頼性の使い方 BFI 系の高い信頼性は Prior をそこそこ硬く置ける根拠。数字の当て込みはパイロットデータで校正してください。Wiley Online Library+1

受け入れ基準（例）
1. 同一入力に対し、μₚ/σₚ²が決定論的に再現（誤差±1e−6）。
2. Posterior 分散 < Prior 分散 かつ Posterior 分散 < 観測分散（正規—正規の必然）。Bookdown
3. 0–1/T の二系統を常に保存し、norm_version が空でない。
4. 分散に下限を適用し、NIST/StatCan が指摘する偏りリスク（過小分散の支配）を抑制。NIST+1
5. 逐次 vs 一括で最終 Posterior が一致（カルマン/ベイズ同値の性質）。arXiv

整合性チェック（5回）
1. 数式と実装の一致：実装は Normal–Normal の公式通り（精度和・精度重み）。OK。Bookdown
2. スケール一貫性：T と 0–1 を同時保持し、入出力スキーマで明示。二重正規化なし。OK。
3. 逐次更新と理論：逐次処理＝静止カルマンの一歩、理論的に妥当。OK。arXiv+1
4. 分散設計の安全策：NIST/StatCan の指摘を踏まえ下限・平滑化を採用。OK。NIST+1
5. 心理測定の前提：Big Five の信頼性エビデンスに整合（Prior を硬めに設定する根拠）。OK。Wiley Online Library+1

必要なら、n8n Function の実コード（JS）、分散推定の校正式（最小二乗/対数回帰）、ocean_timeseries の DDLを実務用に即整備してお渡しします。
